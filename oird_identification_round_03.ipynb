{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnorkelMED - Identifying Opioid-Induced Respiratory Depression  \n",
    "\n",
    "The purpose of this analysis is to probabilistically identify which patient visits included an opioid-induced respiratory depression (OIRD) event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis, filter_unlabeled_dataframe\n",
    "from snorkel.labeling.model import MajorityLabelVoter, LabelModel\n",
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "\n",
    "import helper as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp)\n",
    "\n",
    "# global variables\n",
    "ABSTAIN = -1; CONTROL = 0; CASE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load updated training/dev/valid data after labeling from previous round\n",
    "df_train, df_dev, df_valid, df_test = hlp.load_data(round=3)\n",
    "\n",
    "# re-attach numeric data to reflect any updated rules\n",
    "df_train, df_dev = hlp.reattach_numeric_data(df_train, df_dev)\n",
    "\n",
    "# keep confounding diagnoses visits available\n",
    "confounding_diagnosis_present = pd.read_csv('../sd_structured/icd/visits_with_confounding_icd_codes.csv')\n",
    "\n",
    "# made changes in code in to loading confounding diagnoses, so eliminating the redundant columns\n",
    "df_train.drop(['condition_start_date', 'cva', 'sepsis'], axis = 1, inplace = True)\n",
    "df_dev.drop(['condition_start_date', 'cva', 'sepsis'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store Y values for ease of evaluation\n",
    "Y_dev = df_dev['label'].values\n",
    "Y_dev = np.where(Y_dev=='case', 1, 0) \n",
    "\n",
    "#Y_valid = df_valid['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 3 - Add More Learning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying Round 2 Learning Functions, the top probabilities didn’t perform well (only 1 out of 10 were flagged) – notably, very few had any naloxone administration. They were all in the “study group” of “case” based on AHRQ SQL criteria (indicating post-operative respiratory failure), though. So far, there are no manually-adjudicated cases in the dev set (n=70) that do not have a naloxone administration. Therefore, hyper-parameter tuning that strongly weights the naloxone rule would be preferred. Unfortunately, that rule only has ~1.7% coverage in the training set, so additional rules are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to keep track of rule names for easier reference later\n",
    "lfd = dict()\n",
    "\n",
    "@labeling_function()\n",
    "def LF_naloxone_admin(x):\n",
    "    if x['naloxone_admin_prob'] >= 0.75:\n",
    "        if x['counts_naloxone_effective'] > 0:\n",
    "            return CASE\n",
    "        elif x['counts_naloxone_NOT_effective'] > 0:\n",
    "            return CONTROL\n",
    "        else:\n",
    "            return CASE\n",
    "    elif x['naloxone_admin_prob'] < 0.75:\n",
    "        return CONTROL\n",
    "    else:\n",
    "        # if missing\n",
    "        return ABSTAIN\n",
    "lfd['LF_naloxone_admin'] = 0\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_naloxone(x):\n",
    "    # in round 3, adding checks for whether naloxone is effective\n",
    "    # this is similar to the naloxone_admin rule but tries to \n",
    "    # capture patients where it was mentioned but not documented as administered\n",
    "    # per the drug_exposure table\n",
    "    if x['counts_naloxone'] > 0: \n",
    "        if x['counts_naloxone_effective'] > 0:\n",
    "            return CASE\n",
    "        elif x['counts_naloxone_NOT_effective'] > 0:\n",
    "            return CONTROL\n",
    "        # default to case if not suggestion of working or not\n",
    "        else:\n",
    "            return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_naloxone'] = max(lfd.values()) + 1\n",
    "\n",
    "\"\"\"\n",
    "@labeling_function()\n",
    "def LF_respiratory_failure_any(x):\n",
    "    # this ended up being a heavily-weighted rule to lean controls toward cases\n",
    "    # but it had excellent coverage originally - a chat on Spectrum suggested that if \n",
    "    # you only have a few LFs, highly-specific rules are preferred over high-coverage rules\n",
    "    if '1' in x['respiratory_failure_any'].lower(): \n",
    "        # if there is a confounding diagonsis that would make respiratory failure likely\n",
    "        if x['visit_occurrence_id'] in confounding_diagnosis_present['visit_occurrence_id'].unique():\n",
    "            return CONTROL\n",
    "        # if going on a ventilator, not likely to be related to opioids\n",
    "        elif 'yes' in x['eligible_vent'].lower():\n",
    "            return CONTROL\n",
    "        # or if there is a lack of any other evidence to suggest the patient is a case\n",
    "        elif x['counts_naloxone'] == 0 and \\\n",
    "             np.isnan(x['naloxone_admin_prob']) and \\\n",
    "             x['counts_altered_mental_status'] == 0 and \\\n",
    "             x['counts_narcotic_overdose'] == 0 and \\\n",
    "             x['counts_hypoxia'] == 0 and \\\n",
    "             x['counts_decrease_opioids'] == 0:\n",
    "            return CONTROL\n",
    "        #else:\n",
    "        #    return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_respiratory_failure_any'] = max(lfd.values()) + 1\n",
    "\"\"\"\n",
    "\n",
    "@labeling_function()\n",
    "def LF_respiratory_failure_any(x):\n",
    "    # this ended up being a heavily-weighted rule to lean controls toward cases\n",
    "    # but it had excellent coverage originally - a chat on Spectrum suggested that if \n",
    "    # you only have a few LFs, highly-specific rules are preferred over high-coverage rules\n",
    "    if '1' in x['respiratory_failure_any'].lower(): \n",
    "        # if going on a ventilator, not likely to be related to opioids\n",
    "        if 'yes' in x['eligible_vent'].lower():\n",
    "            return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_respiratory_failure_any'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_resp_care_notes(x):\n",
    "    if x['counts_resp_care_notes'] == 0:\n",
    "        return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_resp_care_notes'] = max(lfd.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def LF_counts_no_acute_events(x):\n",
    "    # this ended up being a heavily-weighted rule to lean cases toward controls\n",
    "    # so additional logic checks to see if other \"acute\" things happened during the visit\n",
    "    #   (even if they didn't happen for several days where this was recorded)\n",
    "    if x['counts_no_acute_events'] > 0:\n",
    "        if x['counts_naloxone'] + x['counts_rapid_response'] + x['counts_altered_mental_status'] + \\\n",
    "            x['counts_narcotic_overdose'] + x['counts_hypoxia'] > 0:\n",
    "            return ABSTAIN\n",
    "        return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_no_acute_events'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_altered_mental_status(x):\n",
    "    if x['counts_altered_mental_status'] > 0:\n",
    "        # first check to see whether another condition could be responsible\n",
    "        if x['visit_occurrence_id'] in confounding_diagnosis_present['visit_occurrence_id'].unique(): \n",
    "            return CONTROL\n",
    "        # if no other condition, add support being a case\n",
    "        return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_altered_mental_status'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_narcotic_overdose(x):\n",
    "    if x['counts_narcotic_overdose'] > 0:\n",
    "        return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_narcotic_overdose'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_hypoxia(x):\n",
    "    if x['counts_hypoxia'] > 0:\n",
    "        return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_hypoxia'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_counts_decrease_opioids(x):\n",
    "    if x['counts_decrease_opioids'] > 0:\n",
    "        return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_decrease_opioids'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_confounding_diagnosis_for_rrt(x):\n",
    "    # added new rules in round #3 (i.e., for heart disease [to include arrhythmias] & \n",
    "    # other respiratory disease causes)\n",
    "    if x['visit_occurrence_id'] in confounding_diagnosis_present['visit_occurrence_id'].unique(): \n",
    "        return CONTROL\n",
    "    elif x['counts_rapid_response'] > 0:\n",
    "        return CASE\n",
    "    return ABSTAIN\n",
    "lfd['LF_confounding_diagnosis_for_rrt'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_extended_vent_time(x):\n",
    "    # if on the vent for 4 or more days\n",
    "    if 'yes;;yes;;yes;;yes' in x['eligible_vent'].lower(): \n",
    "        return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_extended_vent_time'] = max(lfd.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 3 Additions\n",
    "@labeling_function()\n",
    "def LF_counts_no_pain_meds(x):\n",
    "    # low coverage but found in the dev set review last time\n",
    "    if x['counts_no_pain_meds'] > 0:\n",
    "        return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_counts_no_pain_meds'] = max(lfd.values()) + 1\n",
    "\n",
    "@labeling_function()\n",
    "def LF_no_support(x):\n",
    "    # find everything that could result in a CASE\n",
    "    if x['counts_naloxone'] == 0 and \\\n",
    "        np.isnan(x['naloxone_admin_prob']) and \\\n",
    "        x['counts_altered_mental_status'] == 0 and \\\n",
    "        x['counts_narcotic_overdose'] == 0 and \\\n",
    "        x['counts_hypoxia'] == 0 and \\\n",
    "        x['counts_decrease_opioids'] == 0 and \\\n",
    "        x['counts_rapid_response'] == 0 and \\\n",
    "        '1' not in x['respiratory_failure_any'].lower():\n",
    "        return CONTROL\n",
    "    return ABSTAIN\n",
    "lfd['LF_no_support'] = max(lfd.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine all relevant LFs\n",
    "lfs = [LF_naloxone_admin,\n",
    "      LF_counts_naloxone,\n",
    "      LF_respiratory_failure_any,\n",
    "      LF_counts_resp_care_notes,\n",
    "      LF_counts_no_acute_events,\n",
    "      LF_counts_altered_mental_status,\n",
    "      LF_counts_narcotic_overdose,\n",
    "      LF_counts_hypoxia,\n",
    "      LF_counts_decrease_opioids,\n",
    "      LF_confounding_diagnosis_for_rrt,\n",
    "      LF_extended_vent_time,\n",
    "      LF_counts_no_pain_meds,\n",
    "      LF_no_support,\n",
    "      ]\n",
    "\n",
    "# apply LFs\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_dev = applier.apply(df=df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# do naloxone mentions pick up on any administrations that the admin probability doesn't?\n",
    "df_dev.iloc[(L_dev[:, lfd['LF_naloxone_admin']]==ABSTAIN) & \\\n",
    "           (L_dev[:, lfd['LF_counts_naloxone']]!=ABSTAIN)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[(L_train[:, lfd['LF_naloxone_admin']]==ABSTAIN) & \\\n",
    "           (L_train[:, lfd['LF_counts_naloxone']]!=ABSTAIN)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.iloc[L_train[:, lfd['LF_naloxone_admin']] == CONTROL]['naloxone_admin_prob'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = get_label_buckets(L_dev[:, lfd['LF_confounding_diagnosis_for_rrt']], \n",
    "                            L_dev[:, lfd['LF_counts_no_acute_events']])\n",
    "df_dev[['label', 'counts_no_acute_events', 'counts_rapid_response', 'cond_sepsis', 'cond_cva',\n",
    "       'cond_resp_disease', 'cond_cv_disease']] \\\n",
    "    .iloc[buckets[(CONTROL, CONTROL)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting to embed altered mental status within the RRT confounding rule \n",
    "# alternatively, add the confounding diagnoses to altered mental status \n",
    "df_dev.iloc[(L_dev[:, lfd['LF_confounding_diagnosis_for_rrt']]==CONTROL) & \\\n",
    "           (L_dev[:, lfd['LF_counts_altered_mental_status']]==CASE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`eligible_vent` had low coverage & low empirical accuracy, and the introduction of `extended_vent_time` (which has higher empirical accuracy) has helped classification. I'm going to try incorporating `eligible_vent` into `respiratory_failure_any` because that rule heavily influences some of the misclassifications. It's rare to go on a vent after being over-narcatized (particularly if not mentioned elsewhere). To keep the high-coverage rule in place, moving eligible vent to resp failure any. If there's a \"yes\" in `eligible_vent`, return `respiratory_failure_any` as CONTROL. \n",
    "\n",
    "It seems that rules with high coverage have get greater influence on the final classification (at least based on what I'm seeing with `respiratory_failure_any` and `confounding_diagnosis_present`). \n",
    "\n",
    "`altered_mental_status` has good coverage but poor empirical accuracy. Now that we have the `confounding_diagnosis_present` rule, I have added those criteria to `altered_mental_status` and it went from about 26% empirical accuracy to 74% empirical accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs.remove(LF_counts_altered_mental_status)\n",
    "lfs.remove(LF_confounding_diagnosis_for_rrt)\n",
    "lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_dev = applier.apply(df=df_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the code can run\n",
    "label_model.fit(L_train=L_train, Y_dev = Y_dev, \n",
    "                n_epochs = 4000, lr = 0.004, #l2 = 0.01,\n",
    "                optimizer = 'adamax', lr_scheduler = 'step', #prec_init = 0.7,\n",
    "                log_freq = 100, seed = 987)\n",
    "analysis = LFAnalysis(L=L_train, lfs=lfs).lf_summary(est_weights=label_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe to hold learned weights for each rule\n",
    "df_cols = ['n_epochs', 'lr', 'lr_scheduler']\n",
    "df_cols.extend(analysis.index)\n",
    "\n",
    "# specify potential hyperparameters\n",
    "n_epochs = [2000, 4000]\n",
    "lr = [0.001, 0.005, 0.01]\n",
    "lr_scheduler = ['step', 'exponential', 'linear']\n",
    "\n",
    "# tune - in round 2, started adding new seeds also (e.g., 987, 456, & 123)\n",
    "SEED = 123\n",
    "df_tune, df_tune_long = hlp.label_model_tuning(lfs, df_cols, \n",
    "                                               L_train, L_dev, Y_dev, \n",
    "                                               n_epochs, lr, lr_scheduler,\n",
    "                                               seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# review best accuracies among development set\n",
    "df_tune[df_tune['accuracy'] == np.max(df_tune['accuracy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scheduler in lr_scheduler:\n",
    "    g = sns.FacetGrid(df_tune_long[df_tune_long['lr_scheduler']==scheduler], \n",
    "                      col='lr', hue='learning_function', col_wrap=3, height=4)\n",
    "    g = (g.map(plt.scatter, 'n_epochs', 'learned_weight')\n",
    "            .add_legend()\n",
    "            .fig.suptitle('Learned Weights Using ' + str(scheduler) + ' Scheduler', \n",
    "                          y=1.05, fontsize=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model.fit(L_train=L_train, Y_dev = Y_dev, n_epochs = 2000, lr = 0.001, optimizer = 'adamax', \n",
    "                lr_scheduler = 'exponential', log_freq = 100, seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs) \\\n",
    "    .lf_summary(est_weights = label_model.get_weights()) \\\n",
    "    .sort_values(by='Learned Weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_acc = majority_model.score(L=L_dev, Y=Y_dev)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_dev, Y=Y_dev)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign probabilities from either majority vote or label model\n",
    "#gen_probs_train = majority_model.predict_proba(L=L_train)\n",
    "#gen_probs_dev = majority_model.predict_proba(L=L_dev)\n",
    "\n",
    "gen_probs_train = label_model.predict_proba(L=L_train)\n",
    "gen_probs_dev = label_model.predict_proba(L=L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hlp.plot_probabilities_histogram(gen_probs_train[:, CASE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_probabilities_histogram(gen_probs_dev[:, CASE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unlabeled rows? \n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=gen_probs_train, L=L_train\n",
    ")\n",
    "print(str(df_train.shape[0] - df_train_filtered.shape[0]) + ' unlabeled rows in training set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Assigned Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_with_probs = df_dev.copy()\n",
    "dev_with_probs['label_model_prob'] = gen_probs_dev[:, CASE]\n",
    "\n",
    "cases_low_prob = dev_with_probs[(dev_with_probs['label']=='case') & \\\n",
    "                                (dev_with_probs['label_model_prob']<=0.5)]\n",
    "controls_high_prob = dev_with_probs[(dev_with_probs['label']=='control') & \\\n",
    "                                    (dev_with_probs['label_model_prob']>0.5)]\n",
    "\n",
    "cols_for_review = ['label',  'age_on_admission',\n",
    "     'label_model_prob', 'naloxone_admin_prob', 'eligible_vent', 'respiratory_failure_any',\n",
    "     'counts_naloxone', 'counts_resp_care_notes', 'counts_rapid_response', \n",
    "     'counts_no_acute_events', 'counts_altered_mental_status', 'counts_narcotic_overdose',\n",
    "     'counts_hypoxia','counts_decrease_opioids', 'counts_naloxone_effective', 'counts_naloxone_NOT_effective',\n",
    "     'cond_sepsis', 'cond_cva', 'cond_resp_disease', 'cond_cv_disease']\n",
    "\n",
    "cases_low_prob[cols_for_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which rules were flagging?\n",
    "L_dev[cases_low_prob.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls_high_prob[cols_for_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_dev[controls_high_prob.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration of associations \n",
    "from matplotlib  import cm\n",
    "\n",
    "df_fig = dev_with_probs.copy()\n",
    "colors = ['red' if p=='case' else 'blue' for p in df_fig['label']]\n",
    "plt.scatter(df_fig['naloxone_admin_prob'],\n",
    "            df_fig['label_model_prob'],\n",
    "            c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigned probabilities of cases\n",
    "plt.hist(dev_with_probs[dev_with_probs['label']=='case']['label_model_prob'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigned probabilities of controls\n",
    "plt.hist(dev_with_probs[dev_with_probs['label']=='control']['label_model_prob'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past round of reviews, a lot of patients were labeled as **cases** even though they didn't have an naloxone administration. Out of curiosity, how well are the updated rules labeling patients as cases who have a naloxone administration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach LabelModel predictions to dataframes\n",
    "train_with_probs = df_train.copy()\n",
    "train_with_probs['label_model_prob'] = gen_probs_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities with any naloxone admin\n",
    "plt.hist(train_with_probs[train_with_probs['naloxone_admin_prob']>=0.75]['label_model_prob'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities with CASE on naloxone_admin LF\n",
    "plt.hist(train_with_probs.iloc[L_train[:, lfd['LF_naloxone_admin']] == CASE]['label_model_prob'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities with low confidence of actual naloxone admin\n",
    "plt.hist(train_with_probs[train_with_probs['naloxone_admin_prob']<0.75]['label_model_prob'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probabilities with NO naloxone admin\n",
    "plt.hist(train_with_probs[train_with_probs['naloxone_admin_prob'].isnull()]['label_model_prob'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach LabelModel predictions to dataframes\n",
    "train_with_probs = df_train.copy()\n",
    "train_with_probs['label_model_prob'] = gen_probs_train[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top 20 highest probabilities from train set\n",
    "top_probs = train_with_probs.nlargest(n=20, columns='label_model_prob')\n",
    "\n",
    "# send half to the dev set & half to the valid set\n",
    "visits_for_dev = top_probs['visit_occurrence_id'].sample(frac=0.5, random_state=123)\n",
    "visits_for_valid = top_probs[~np.isin(top_probs['visit_occurrence_id'], visits_for_dev)]['visit_occurrence_id']\n",
    "\n",
    "# concatenate the respective training set rows to dev & valid sets\n",
    "df_dev4 = pd.concat([df_dev, df_train[df_train['visit_occurrence_id'].isin(visits_for_dev)]], sort=True)\n",
    "df_valid4 = pd.concat([df_valid, df_train[np.isin(df_train['visit_occurrence_id'], visits_for_valid)]], sort=True)\n",
    "\n",
    "# remove the rows from the training set\n",
    "df_train4 = df_train.drop(top_probs.index)\n",
    "\n",
    "assert df_dev4.shape[0] == df_dev.shape[0] + 0.5*top_probs.shape[0]\n",
    "assert df_valid4.shape[0] == df_valid.shape[0] + 0.5*top_probs.shape[0]\n",
    "assert df_train4.shape[0] == df_train.shape[0] - top_probs.shape[0]\n",
    "assert not np.isin(df_train4['visit_occurrence_id'], df_dev4['visit_occurrence_id']).any()\n",
    "assert not np.isin(df_train4['visit_occurrence_id'], df_valid4['visit_occurrence_id']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for manual review - making a copy for being labeled/manipulated & 1 without\n",
    "#df_train4.to_csv('./train_set4.csv', index=False)\n",
    "#df_train4.to_csv('./train_set4_labeled.csv', index=False)\n",
    "#df_dev4.to_csv('./dev_set4.csv', index=False)\n",
    "#df_dev4.to_csv('./dev_set4_labeled.csv', index=False)\n",
    "#df_valid4.to_csv('./valid_set4.csv', index=False)\n",
    "#df_valid4.to_csv('./valid_set4_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export working file for building code - not to be used for final analysis\n",
    "train_with_probs.to_csv('./train_set_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
